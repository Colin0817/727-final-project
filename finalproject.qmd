---
title: "app_claude"
format: pdf
editor: visual
---

```{r}
library(readxl)
#导入ChatGPT四个平台评论
chatgpt_app <- read_excel("/Users/jiangyujing/Documents/727/final project/1appstore_chatgpt.xlsx")
chatgpt_google <-read_excel("/Users/jiangyujing/Documents/727/final project/3google_gpt.xlsx")
chatgpt_reddit <-read_excel("/Users/jiangyujing/Documents/727/final project/5reddit_gpt.xlsx")
chatgpt_youtube <-read_excel("/Users/jiangyujing/Documents/727/final project/7youtube_gpt.xlsx")
#导入claude四个平台评论
claude_app <- read_excel("/Users/jiangyujing/Documents/727/final project/2appstore_claude.xlsx")
claude_google <-read_excel("/Users/jiangyujing/Documents/727/final project/4google_claude.xlsx")
claude_reddit <-read_excel("/Users/jiangyujing/Documents/727/final project/6reddit_claude.xlsx")
claude_youtube <-read_excel("/Users/jiangyujing/Documents/727/final project/8youtube_claude.xlsx")
```

```{r}
library(tm)
library(tidytext)
library(tidyr)
library(textdata)
library(text)
library(topicmodels)
library(wordcloud)
library(ggplot2)
library(tidyverse)
library(syuzhet)
library(gridExtra)
library(SnowballC)
library(dplyr)
```

```{r}
cleaned_app_gpt <- chatgpt_app %>%
  mutate(document_id = row_number())%>%
  mutate(text = content)
cleaned_app_gpt <- cleaned_app_gpt %>%
  mutate(text = str_to_lower(text)) %>%
  mutate(text = removePunctuation(text)) %>%
  mutate(text = removeNumbers(text)) %>%
  mutate(text = removeWords(text, stopwords("en"))) %>%
  mutate(text = stripWhitespace(text))


cleaned_app_claude <- claude_app %>%
  mutate(document_id = row_number())%>%
  mutate(text = content)
cleaned_app_claude <- cleaned_app_claude %>%
  mutate(text = str_to_lower(text)) %>%
  mutate(text = removePunctuation(text)) %>%
  mutate(text = removeNumbers(text)) %>%
  mutate(text = removeWords(text, stopwords("en"))) %>%
  mutate(text = stripWhitespace(text))

cleaned_google_gpt <- chatgpt_google %>%
  mutate(document_id = row_number())%>%
  mutate(text = content)
cleaned_google_gpt <- cleaned_google_gpt %>%
  mutate(text = str_to_lower(text)) %>%
  mutate(text = removePunctuation(text)) %>%
  mutate(text = removeNumbers(text)) %>%
  mutate(text = removeWords(text, stopwords("en"))) %>%
  mutate(text = stripWhitespace(text))

cleaned_google_claude <- claude_google %>%
  mutate(document_id = row_number())%>%
  mutate(text = content)
# 文本清理
cleaned_google_claude <- cleaned_google_claude %>%
  mutate(text = str_to_lower(text)) %>%
  mutate(text = removePunctuation(text)) %>%
  mutate(text = removeNumbers(text)) %>%
  mutate(text = removeWords(text, stopwords("en"))) %>%
  mutate(text = stripWhitespace(text))
```

```{r}
# 监督学习：特定概念提取
#定义特定概念的词典
price_keywords <- c("price", "cost", "expensive", "cheap", "value", "affordable", "worth", "free", "subscription", "costly","inexpensive","budget")
performance_keywords <- c("performance", "speed", "efficient", "quality", "accuracy", "reliable", "lag", "fast", "smooth", "slow", "output","limit","limited","delay","quick","correct","reliability")
support_keywords <- c("support", "customer service", "help", "responsive", "team", "issues", "bug", "contact", "solve", "response time", "feedback", "documentation","helpful","troubleshooting","assistance","FAQ")
usability_keywords <- c("easy", "intuitive", "interface", "design", "user-friendly", "simple", "complex", "accessible", "learning curve", "interaction", "navigation","setup","customization")
# 提取包含这些关键词的评论
#appstore_chatgpt
price_comments1 <- cleaned_app_gpt %>%
  filter(str_detect(text, str_c(price_keywords, collapse = "|")))
##这里需要计数。每个维度在总体中的占比；四个平台分开来。之后，展示四个维度在四个平台被提及的频率
performance_comments1 <- cleaned_app_gpt %>%
  filter(str_detect(text, str_c(performance_keywords, collapse = "|")))
support_comments1 <- cleaned_app_gpt %>%
  filter(str_detect(text, str_c(support_keywords, collapse = "|")))
usability_comments1 <- cleaned_app_gpt %>%
  filter(str_detect(text, str_c(usability_keywords, collapse = "|")))

#appstore_claude
price_comments2 <- cleaned_app_claude %>%
  filter(str_detect(text, str_c(price_keywords, collapse = "|")))
performance_comments2 <- cleaned_app_claude %>%
  filter(str_detect(text, str_c(performance_keywords, collapse = "|")))
support_comments2 <- cleaned_app_claude %>%
  filter(str_detect(text, str_c(support_keywords, collapse = "|")))
usability_comments2 <- cleaned_app_claude %>%
  filter(str_detect(text, str_c(usability_keywords, collapse = "|")))

#googleplay_chatgpt
price_comments3 <- cleaned_google_gpt %>%
  filter(str_detect(text, str_c(price_keywords, collapse = "|")))
performance_comments3 <- cleaned_google_gpt %>%
  filter(str_detect(text, str_c(performance_keywords, collapse = "|")))
support_comments3 <- cleaned_google_gpt %>%
  filter(str_detect(text, str_c(support_keywords, collapse = "|")))
usability_comments3 <- cleaned_google_gpt %>%
  filter(str_detect(text, str_c(usability_keywords, collapse = "|")))

#googleplay_claude
price_comments4 <- cleaned_google_claude %>%
  filter(str_detect(text, str_c(price_keywords, collapse = "|")))
performance_comments4 <- cleaned_google_claude %>%
  filter(str_detect(text, str_c(performance_keywords, collapse = "|")))
support_comments4 <- cleaned_google_claude %>%
  filter(str_detect(text, str_c(support_keywords, collapse = "|")))
usability_comments4 <- cleaned_google_claude %>%
  filter(str_detect(text, str_c(usability_keywords, collapse = "|")))
```

```{r}
library(dplyr)

# 加载 AFINN 词典
afinn_sentiments <- get_sentiments("afinn")

# 定义函数以减少重复代码
analyze_sentiments <- function(comments) {
  comments %>%
    mutate(id = row_number()) %>%                # 为每条评论添加唯一 ID
    unnest_tokens(word, content) %>%             # 拆分评论为单词
    left_join(afinn_sentiments, by = "word") %>% # 匹配 AFINN 情感词典
    mutate(value = replace_na(value, 0)) %>%     # 未匹配单词分数设为 0
    group_by(id) %>%                             # 按评论 ID 分组
    summarize(score = sum(value), .groups = "drop") %>% # 计算情感总分
    mutate(sentiment = case_when(
      score > 0 ~ "positive",
      score < 0 ~ "negative",
      TRUE ~ "neutral"
    )) %>%
    count(sentiment, sort = TRUE) %>%            # 统计每种情感类别的数量
    mutate(proportion = n / sum(n))              # 计算每种情感的占比
}

# 对不同维度的评论进行情感分析
price_sentiments1 <- analyze_sentiments(price_comments1)
performance_sentiments1 <- analyze_sentiments(performance_comments1)
support_sentiments1 <- analyze_sentiments(support_comments1)
usability_sentiments1 <- analyze_sentiments(usability_comments1)

price_sentiments2 <- analyze_sentiments(price_comments2)
performance_sentiments2 <- analyze_sentiments(performance_comments2)
support_sentiments2 <- analyze_sentiments(support_comments2)
usability_sentiments2 <- analyze_sentiments(usability_comments2)

price_sentiments3 <- analyze_sentiments(price_comments3)
performance_sentiments3 <- analyze_sentiments(performance_comments3)
support_sentiments3 <- analyze_sentiments(support_comments3)
usability_sentiments3 <- analyze_sentiments(usability_comments3)

price_sentiments4 <- analyze_sentiments(price_comments4)
performance_sentiments4 <- analyze_sentiments(performance_comments4)
support_sentiments4 <- analyze_sentiments(support_comments4)
usability_sentiments4 <- analyze_sentiments(usability_comments4)

app_gpt_sentiment <- bind_rows(
  mutate(price_sentiments1, dimension = "price",label = "app_gpt"),
  mutate(performance_sentiments1, dimension = "performance",label = "app_gpt"),
  mutate(support_sentiments1, dimension = "support",label = "app_gpt"),
  mutate(usability_sentiments1, dimension = "usability",label = "app_gpt")
)
print(app_gpt_sentiment)

app_claude_sentiment <- bind_rows(
  mutate(price_sentiments2, dimension = "price",label = "app_claude"),
  mutate(performance_sentiments2, dimension = "performance",label = "app_claude"),
  mutate(support_sentiments2, dimension = "support",label = "app_claude"),
  mutate(usability_sentiments2, dimension = "usability",label = "app_claude")
)
print(app_claude_sentiment)

google_gpt_sentiment <- bind_rows(
  mutate(price_sentiments3, dimension = "price",label = "google_gpt"),
  mutate(performance_sentiments3, dimension = "performance",label = "google_gpt"),
  mutate(support_sentiments3, dimension = "support",label = "google_gpt"),
  mutate(usability_sentiments3, dimension = "usability",label = "google_gpt")
)
print(google_gpt_sentiment)

google_claude_sentiment <- bind_rows(
  mutate(price_sentiments4, dimension = "price",label = "google_claude"),
  mutate(performance_sentiments4, dimension = "performance",label = "google_claude"),
  mutate(support_sentiments4, dimension = "support",label = "google_claude"),
  mutate(usability_sentiments4, dimension = "usability",label = "google_claude")
)
print(google_claude_sentiment)
```
```{r}
# 这里开始计算并合并reddit和youtube的情感数据
calculate_sentiment_by_dimension <- function(data, dimension_col, sentiment_col, dimension_value) {
  # 过滤出包含指定维度的评论
  data_filtered <- data %>%
    mutate(original_row = row_number()) %>%
    separate_rows(!!sym(dimension_col), sep = ",\\s*") %>%
    filter(!!sym(dimension_col) == dimension_value)  # 只保留指定维度的评论
  
  # 统计包含指定维度的评论总数
  total_comments <- nrow(data_filtered)
  
  # 统计每个情感的频数并计算占比
  sentiment_proportions <- data_filtered %>%
    group_by(!!sym(sentiment_col)) %>%
    summarize(count = n_distinct(original_row), .groups = 'drop') %>%  # 去重统计
    mutate(proportion = count / total_comments)  # 计算占比
  sentiment_proportions <- sentiment_proportions %>%
    complete(!!sym(sentiment_col), fill = list(count = 0, proportion = 0)) %>%
    mutate(proportion = count / total_comments)
  # 返回结果
  return(sentiment_proportions)
}

# 计算各维度下的情感占比
price_sentiments5 <- calculate_sentiment_by_dimension(chatgpt_reddit, 'dimension', 'sentiment', 'price')
performance_sentiments5 <- calculate_sentiment_by_dimension(chatgpt_reddit, 'dimension', 'sentiment', 'performance')
support_sentiments5 <- calculate_sentiment_by_dimension(chatgpt_reddit, 'dimension', 'sentiment', 'support')
usability_sentiments5 <- calculate_sentiment_by_dimension(chatgpt_reddit, 'dimension', 'sentiment', 'usability')

price_sentiments6 <- calculate_sentiment_by_dimension(claude_reddit, 'dimension', 'sentiment', 'price')
performance_sentiments6 <- calculate_sentiment_by_dimension(claude_reddit, 'dimension', 'sentiment', 'performance')
support_sentiments6 <- calculate_sentiment_by_dimension(claude_reddit, 'dimension', 'sentiment', 'support')
usability_sentiments6 <- calculate_sentiment_by_dimension(claude_reddit, 'dimension', 'sentiment', 'usability')

price_sentiments7 <- calculate_sentiment_by_dimension(chatgpt_youtube, 'dimension', 'sentiment', 'price')
performance_sentiments7 <- calculate_sentiment_by_dimension(chatgpt_youtube, 'dimension', 'sentiment', 'performance')
support_sentiments7 <- calculate_sentiment_by_dimension(chatgpt_youtube, 'dimension', 'sentiment', 'support')
usability_sentiments7 <- calculate_sentiment_by_dimension(chatgpt_youtube, 'dimension', 'sentiment', 'usability')

price_sentiments8 <- calculate_sentiment_by_dimension(claude_youtube, 'dimension', 'sentiment', 'price')
performance_sentiments8 <- calculate_sentiment_by_dimension(claude_youtube, 'dimension', 'sentiment', 'performance')
support_sentiments8 <- calculate_sentiment_by_dimension(claude_youtube, 'dimension', 'sentiment', 'support')
usability_sentiments8 <- calculate_sentiment_by_dimension(claude_youtube, 'dimension', 'sentiment', 'usability')

##下面进行合并
reddit_gpt_sentiment <- bind_rows(
  mutate(price_sentiments5, dimension = "price",label = "reddit_gpt"),
  mutate(performance_sentiments5, dimension = "performance",label = "reddit_gpt"),
  mutate(support_sentiments5, dimension = "support",label = "reddit_gpt"),
  mutate(usability_sentiments5, dimension = "usability",label = "reddit_gpt")
)
print(reddit_gpt_sentiment)

reddit_claude_sentiment <- bind_rows(
  mutate(price_sentiments6, dimension = "price",label = "reddit_claude"),
  mutate(performance_sentiments6, dimension = "performance",label = "reddit_claude"),
  mutate(support_sentiments6, dimension = "support",label = "reddit_claude"),
  mutate(usability_sentiments6, dimension = "usability",label = "reddit_claude")
)
print(reddit_claude_sentiment)

youtube_gpt_sentiment <- bind_rows(
  mutate(price_sentiments7, dimension = "price",label = "youtube_gpt"),
  mutate(performance_sentiments7, dimension = "performance",label = "youtube_gpt"),
  mutate(support_sentiments7, dimension = "support",label = "youtube_gpt"),
  mutate(usability_sentiments7, dimension = "usability",label = "youtube_gpt")
)
print(youtube_gpt_sentiment)

youtube_claude_sentiment <- bind_rows(
  mutate(price_sentiments8, dimension = "price",label = "youtube_claude"),
  mutate(performance_sentiments8, dimension = "performance",label = "youtube_claude"),
  mutate(support_sentiments8, dimension = "support",label = "youtube_claude"),
  mutate(usability_sentiments8, dimension = "usability",label = "youtube_claude")
)
print(youtube_claude_sentiment)

```
```{r}
#调整youtube-gpt
# 创建缺失情感数据的表
missing_sentiments <- tibble(
  sentiment = c("POSITIVE", "NEUTRAL", "POSITIVE", "NEGATIVE", "POSITIVE", "NEUTRAL"),
  count = c(0, 0, 0, 0, 0, 0),
  proportion = c(0, 0, 0, 0, 0, 0),
  dimension = c("price", "price", "performance", "performance", "support", "support"),
  label = rep("youtube_gpt", 6)  # 添加 label 列并重复值
)

# 假设 youtube_gpt_sentiment 已经存在
# 将 missing_sentiments 合并到 youtube_gpt_sentiment 中
youtube_gpt_sentiment <- bind_rows(youtube_gpt_sentiment, missing_sentiments)

# 查看合并后的数据
print(youtube_gpt_sentiment)

```

```{r}
calculate_proportions <- function(total_data, ...){
  # 获取输入的各维度数据集
  dimensions <- list(...)
  # 计算总体评论数
  total_count <- nrow(total_data)
  # 初始化计数和占比向量
  counts <- sapply(dimensions, nrow)
  proportions <- counts / total_count
  # 创建结果数据框
  dimension_proportions <- data.frame(
    dimension = names(dimensions),
    count = counts,
    proportion = proportions
  )
  # 返回结果
  return(dimension_proportions)
}

# 使用函数
dimension_proportions_app_gpt <- calculate_proportions(
  total_data = cleaned_app_gpt,
  price = price_comments1,
  performance = performance_comments1,
  support = support_comments1,
  usability = usability_comments1
)

dimension_proportions_app_claude <- calculate_proportions(
  total_data = cleaned_app_claude,
  price = price_comments2,
  performance = performance_comments2,
  support = support_comments2,
  usability = usability_comments2
)

dimension_proportions_google_gpt <- calculate_proportions(
  total_data = cleaned_google_gpt,
  price = price_comments3,
  performance = performance_comments3,
  support = support_comments3,
  usability = usability_comments3
)

dimension_proportions_google_claude <- calculate_proportions(
  total_data = cleaned_google_claude,
  price = price_comments4,
  performance = performance_comments4,
  support = support_comments4,
  usability = usability_comments4
)
```

```{r}
#下面来处理reddit和youtube
calculate_dimension_proportions <- function(data, dimension_col) {
  library(tidyr)
  
  # 获取原始评论总数
  total_comments <- nrow(data)  # 原始数据行数
  
  # 拆分维度列
  data_split <- data %>%
    mutate(original_row = row_number()) %>%  # 添加原始行号
    separate_rows(!!sym(dimension_col), sep = ",\\s*")  # 拆分多维度记录
  
  # 统计每个维度的评论数并计算占比
  dimension_proportions <- data_split %>%
    filter(!is.na(!!sym(dimension_col))) %>%  # 忽略 NA
    group_by(!!sym(dimension_col)) %>%
    summarize(count = n_distinct(original_row)) %>%  # 去重统计
    mutate(proportion = count / total_comments)  # 计算占比
  
  # 返回结果
  return(dimension_proportions)
}
dimension_proportions_reddit_gpt <- calculate_dimension_proportions(chatgpt_reddit, "dimension")
print(dimension_proportions_reddit_gpt)

dimension_proportions_reddit_claude <- calculate_dimension_proportions(claude_reddit, "dimension")
print(dimension_proportions_reddit_claude)

dimension_proportions_youtube_gpt <- calculate_dimension_proportions(chatgpt_youtube, "dimension")
print(dimension_proportions_youtube_gpt)

dimension_proportions_youtube_claude <- calculate_dimension_proportions(claude_youtube, "dimension")
print(dimension_proportions_youtube_claude)
```


```{r}
##对算出占比的八个数据集进行合并，这里是维度
dimension_proportions_app_gpt <- dimension_proportions_app_gpt %>%
  mutate(platform = "App Store", app = "ChatGPT")

dimension_proportions_google_gpt <- dimension_proportions_google_gpt %>%
  mutate(platform = "Google Play", app = "ChatGPT")

dimension_proportions_youtube_gpt <- dimension_proportions_youtube_gpt %>%
  mutate(platform = "YouTube", app = "ChatGPT")

dimension_proportions_reddit_gpt <- dimension_proportions_reddit_gpt %>%
  mutate(platform = "Reddit", app = "ChatGPT")


dimension_proportions_app_claude <- dimension_proportions_app_claude %>%
  mutate(platform = "App Store", app = "Claude")

dimension_proportions_google_claude <- dimension_proportions_google_claude %>%
  mutate(platform = "Google Play", app = "Claude")

dimension_proportions_youtube_claude <- dimension_proportions_youtube_claude %>%
  mutate(platform = "YouTube", app = "Claude")

dimension_proportions_reddit_claude <- dimension_proportions_reddit_claude %>%
  mutate(platform = "Reddit", app = "Claude")

# 合并所有数据集
dimension_proportions_gpt <- rbind(
  dimension_proportions_app_gpt,
  dimension_proportions_google_gpt,
  dimension_proportions_reddit_gpt,
  dimension_proportions_youtube_gpt
  )

dimension_proportions_claude <- rbind(
  dimension_proportions_app_claude,
  dimension_proportions_google_claude,
  dimension_proportions_reddit_claude,
  dimension_proportions_youtube_claude)
# 查看合并后的数据
print(dimension_proportions_gpt)
print(dimension_proportions_claude)
```

```{r}
##热力图：情感合并
library(stringr)
combined_data <- bind_rows(app_gpt_sentiment, app_claude_sentiment, google_gpt_sentiment, google_claude_sentiment, reddit_gpt_sentiment, reddit_claude_sentiment, youtube_gpt_sentiment, youtube_claude_sentiment)
combined_data <- combined_data %>%
  mutate(sentiment = str_to_lower(sentiment))
print(combined_data)
```



```{r}
positive_data <- combined_data %>%
  filter(sentiment == "positive")
print(positive_data)
```


```{r}
library(RColorBrewer)
library(viridis)
heatmap_gpt <- ggplot(positive_data, aes(x = label, y = dimension, fill = proportion)) +
  geom_tile() +
  scale_fill_viridis(option = "mako") +
  labs(title = "Sentiment Proportions by Dimension",
       x = "Platform",
       y = "Dimension",
       fill = "Proportion") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # 旋转x轴标签
```

```{r}
library(plotly)
interactive_heatmap <- ggplotly(heatmap_gpt)
interactive_heatmap
```
```{r}
library(htmlwidgets)

# 保存为 HTML 文件
saveWidget(interactive_heatmap, "interactive_heatmap.html")

```


```{r}
##差评
negative_data <- combined_data %>%
  filter(sentiment == "negative")
ggplot(negative_data, aes(x = label, y = dimension, fill = proportion)) +
  geom_tile() +
  scale_fill_viridis(option = "plasma") +
  labs(title = "Sentiment Proportions by Dimension",
       x = "Platform",
       y = "Dimension",
       fill = "Proportion") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
neutral_data <- combined_data %>%
  filter(sentiment == "neutral")
ggplot(neutral_data, aes(x = label, y = dimension, fill = proportion)) +
  geom_tile() +
  scale_fill_viridis(option = "plasma") +
  labs(title = "Sentiment Proportions by Dimension",
       x = "Platform",
       y = "Dimension",
       fill = "Proportion") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
